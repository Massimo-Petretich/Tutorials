---
title: "Nascent transcriptomics"
author: "Massimo Petretich"
date: "7/2/2020"
output:
  html_document:
    toc: true
    number_sections: true
---


# Introduction

## SLAM-seq method
The SLAM-seq is a RNA-seq method belonging to the "nascent transcriptomocs" family. SLAM-seq compared to other methods within the family (such as GRO-seq, PRO-seq and NET-seq) is a newer method and therefore less prominent in the literature. The main difference to the methods mentioned earlier is that the nascnt RNA is labeled with a modified nucleotide rather than being physically isolated (from RNA-PolII complexes in the case of the NET-seq, from biotinilated RNA in the case of GRO-seq and PRO-seq). In particular, the modified nucleotide used (S4U or thiouridine) after alchylation causes a specific mutation (T --> C) to happen during reverse transcription.
For a more detailed overview of the method, please refer to the publication: https://pubmed.ncbi.nlm.nih.gov/29622725/

## Fastq files processing with Slamdunk
The fastq files processing is done using the Slamdunk python module: http://t-neumann.github.io/slamdunk/docs.html#document-Quickstart
In brief, for each sample a table containing the total read-counts and the nascent read-count is generated. 


```{r, message = FALSE}
library(LSD)
library(ggplot2)
library(MASS)
library(viridis)
library(org.Hs.eg.db)
library(tidyverse)
library(DESeq2)

options(max.print = 200)
par(col.main = "grey30")
par(col.lab = "grey30")
par(col.sub = "grey30")
par(col.axis = "grey30")

setwd("C:/Users/mp674001/OneDrive - GSK/Desktop/SLAMseq")
```

# Standard workflow
This experiment is composed of 3 timepoints: 3h, 5h and 24h. The number of hours correspond to the experimental treatment and not the S4U labeling time. 3h and 5h libraries are SLAM-seq libraries, the S4U labeling was performed for 2h only (the 2h at the end of the treatment). The reason for this is to ensure that the transcriptional response caused by the treatments is already started by the time the S4U is added. The actual library preparation is carried out with the 3-RNA-seq method (aka PolyA-seq). The 24h samples are normal 3' RNA-seq libraries. The reason why SLAM-seq libraries were not made for this timepoint is simply that the treatment time is fairly long and therefore, most transcript would have had the chance to undergo a complete turnover, this implies that transcriptional changes should be detectable with a standard 3' RNA-seq library at this point. As concern the conditions, the experiment is composed of 3 perturbations (B, C, D) and reference condition (A).

## Counts processing
### Experiment layout
```{r}
metadata <- read.csv("./Metadata.csv", stringsAsFactors = F)
metadata
```

### Import the count data from slamdunk
```{r}
table_extract <- function(directory, treshold_low_total_counts) {
  
  files <- list.files(directory, 
                         pattern = "mapped_filtered_tcount.tsv",
                         recursive = T, 
                         full.names = T
  )
  
  cts_list <- lapply(
    X = files, 
    FUN = function(x) {
      y <- read.delim(x, comment.char = "#")
      y$Name <- as.character(y$Name)
      return(y)
      }
    )
  
  print("Head of slamdunk count")
  print(head(cts_list[[1]]))
  
  names(cts_list) <- basename(files) %>% gsub(pattern = "_slamdunk_mapped_filtered_tcount.tsv", replacement = "")
  cts_list <- cts_list[metadata$Sample_Name]

  cts_nascent <- sapply(cts_list, function(x) x$TcReadCount) # extract the nascent read count from all datasets
  rownames(cts_nascent) <- as.character(cts_list[[1]]$Name) 
  
  cts_total <- sapply(cts_list, function(x) x$ReadCount) # extract the total read count from all datasets
  rownames(cts_total) <- as.character(cts_list[[1]]$Name)
  
  cts_nascent <- cts_nascent[order(rowSums(cts_total), decreasing = T), ]
  cts_total <- cts_total[order(rowSums(cts_total), decreasing = T), ]
  
  cts_nascent <- cts_nascent[! duplicated(rownames(cts_total)), ] # we have a small amount of transcripts that have multiple UTRs annotated, by ordering and then remove the duplicates in the gene names we keep only the UTR with the highest counts
  cts_total <- cts_total[! duplicated(rownames(cts_total)), ]
  
  cts_nascent <- cts_nascent[rowSums(cts_total) > treshold_low_total_counts, ] # filter out all those transcripts with too little expression
  cts_total <- cts_total[rowSums(cts_total) > treshold_low_total_counts, ]
  
  rownames(cts_nascent) <- sapply(strsplit(rownames(cts_nascent), "\\."), function(x) x[[1]])
  rownames(cts_total) <- sapply(strsplit(rownames(cts_total), "\\."), function(x) x[[1]])
  
  cts_list <- list(total = cts_total, nascent = cts_nascent)
}


cts_list <- table_extract(directory = "./Count_files", treshold_low_total_counts = 10)

print("Genes by samples read-count matrix")
cts_list
```

#### Sequencing depth stats
```{r, eval=FALSE}
dir.create("./Plots/")

# Total reads stats
jpeg(
  filename = "./Plots/Total_reads_stats.jpg", 
  width = 20, 
  height = 8, 
  units = "cm", 
  res = 140, 
  quality = 100
  )
  par(mar = c(6,6,0.2,0.2))
  lapply(cts_list, colSums) %>% Reduce(f = "rbind") %>% 
    barplot(
      las = 2, 
      cex.lab = 1, cex.names = 1,
      beside = T
      )
dev.off()
```

<img src="C:/Users/mp674001/OneDrive - GSK/Desktop/SLAMseq/Plots/Total_reads_stats.jpg" height="300" />
<br>
For each sample, respectively total and nascent (total) read counts are shown. The 24h samples (standard 3' library) were sequenced far less deep compared to the SLAM-seq libraries. The aim was to have similar coverage between these samples and the nascent libraries.

```{r, eval=FALSE}
# Nascent reads proportion stats
jpeg(
  filename = "./Plots/Nascent_reads_proportion_stats.jpg", 
  width = 20, 
  height = 8, 
  units = "cm", 
  res = 140, 
  quality = 100
  )
  par(mar = c(6,6,0.2,0.2))
  lapply(cts_list, colSums) %>% 
    rev() %>% 
    Reduce(f = `/`) %>% 
    barplot(
      las = 2, 
      ylab = "Proportion of\nnascent reads", 
      cex.lab = 1, cex.names = 1,
      col = "grey50"
      )
dev.off()
```

<img src="C:/Users/mp674001/OneDrive - GSK/Desktop/SLAMseq/Plots/Nascent_reads_proportion_stats.jpg" height="300" />
<br>
Note that samples 13-24 are standard 3'-RNA-seq and not SLAM-seq. The small yet detectable T-->C conversion is a background noise likely due to SNPs caracteristic of the cell line used. 


### Annotate the transcripts by gene symbols
```{r, eval=FALSE}
annotation_to_symbol <- function(x, annotation) {
  nascent <- x$nascent
  total <- x$total
  
  symbols <-  AnnotationDbi::select(x = org.Hs.eg.db, keys = rownames(total), columns =  "SYMBOL", keytype =  annotation)
  colnames(symbols)[1] <- "Old"
  symbols <- symbols[! is.na(symbols$SYMBOL), ]
  symbols <- symbols[! duplicated(symbols$SYMBOL), ]
  symbols <- symbols[! duplicated(symbols$Old), ]
  
  total <- total[symbols$Old, ]
  nascent <- nascent[symbols$Old, ]
  
  rownames(total) <- symbols$SYMBOL
  rownames(nascent) <- symbols$SYMBOL
  
  return(list(total = total, nascent = nascent))
}

cts_list_symbols <- annotation_to_symbol(cts_list, "ENTREZID")
```

## Counts and metadata wrangling
```{r, eval=FALSE}
# Each group of datasets (condition, Nascent/total) is processed in DESeq2 independently
metadata_list <- split(metadata, metadata$Time)

# Create the corresponding count matrixes
cts_list_DESeq2 <- list(
    Nascent_3h = cts_list_symbols$nascent[, colnames(cts_list_symbols$nascent) %in% metadata_list$`3h`$Sample_Name], 
    Total_3h = cts_list_symbols$total[, colnames(cts_list_symbols$total) %in% metadata_list$`3h`$Sample_Name], 
    Nascent_5h = cts_list_symbols$nascent[, colnames(cts_list_symbols$nascent) %in% metadata_list$`5h`$Sample_Name], 
    Total_5h = cts_list_symbols$total[, colnames(cts_list_symbols$total) %in% metadata_list$`5h`$Sample_Name], 
    Total_24h = cts_list_symbols$total[, colnames(cts_list_symbols$total) %in% metadata_list$`24h`$Sample_Name]
    )


metadata_list <- metadata_list[c("3h", "3h", "5h", "5h", "24h")] # follow the order of the elements on cts_list_DESeq2 (3h nascent, 3h total, ..., 24h total)
names(metadata_list) <- names(cts_list_DESeq2)

# Drop unused levels (not necessary in this analysis, done as general good practice)
metadata_list <- lapply(metadata_list, 
                        function(x) {
                          x$Treatment <- factor(x$Treatment, levels = unique(x$Treatment))
                          return(x)
                          }
                        )

metadata_list
```

## DEseq2
```{r, eval=FALSE}
dds_list <- lapply(names(metadata_list), 
                   function(nm) DESeqDataSetFromMatrix(
                     countData = cts_list_DESeq2[[nm]], 
                     colData = metadata_list[[nm]], 
                     design = ~ Treatment
                     )
                   )

dds_list <- lapply(dds_list, DESeq)

names(dds_list) <- names(metadata_list)

res_list <- lapply(1:length(dds_list), function(i) {
  all_levels <- levels(metadata_list[[i]]$Treatment)
  A_level_index <- grep(pattern = "A", all_levels)
  A_level <- all_levels[A_level_index]
  all_levels_no_A <- all_levels[- A_level_index]
  z <- lapply(all_levels_no_A, 
              function(x) {
                y <- lfcShrink(dds_list[[i]], contrast = c("Treatment", x, A_level))
                return(y)
              }
  )
  names(z) <- all_levels_no_A
  return(z)
}
)

names(res_list) <- names(dds_list)
```


# Correct the nascent dataset for global effects
In this section we correct for effects that are spread across the majority of the transcripts. This situation can happen whenever a perturbation affects a protein invilved in "global" transcription, one example of this might be given by knoclout of different proteins such as c-Myc , RNA-PolII subunits, elongation factors and many others. These perturbations tend to have an effect on the whole population of transcripts that are expressed (of course, normally there are also some populations of transcripts that do not follow this trend or that show particularly strong changes). Standard transcriptomic methods do not allow the identification of these "global" effects due to a very simple assumption: most transcripts do not change in expression. Importantly, this assumption is one of the pilars of the "borrowing strength" concept behind the statistics of many widespread differential-expression packages sucha as DEseq2, LIMMA, DESeq etc. <br>
In order to account for such effects, noormally, a spike-in RNA is necessary, for example if the experiment is done in human cells, fly cells are introduced into the samples in fixed proportions. The process of referring the human transcripts to the fly transcriptome allows to identify the global effect. <br>
In SLAM-seq this is not necessary. One of the powers of the method lies in its (apparent) weakness: most of the reads are not used for nascent transcriptomics analysis. In an experiment such as the one analysed here, where the S4U is provided to the cells for just a brief amount of time, only ~5% of the reads are labeled (T to C conversion, see the "Nascent reads proportion" stats). This means that one would disregard 95% of the reads if interested in just the nascent effects. These reads can be very useful since they can be used as an internal spike-in. <br>
The key of the procedure is to extract from the DESeq2 object the normalization coefficients between the samples (in DESeq2 called "size factors"). In theory one could use the size factors of the total library (basically indistinguishable from the non-nascent one) and use those size factors also for the nascent libraries. This approach would lead to some artefacts since there is a linear relationship binding the amount of reads in the nascent library to the ones in the total libraries. Therefore, the strategy used here is to fit a linear model between the 2 types of libraries and take the fitted values. Here we did also something else, we removed from the linear model those samples corresponding to the condition (condition 'B') assumed to present "global" effects. One could argue that this is a biased approach, and that using all the samples to build the model would be the most conservative approach. It might be true, but here we opted for removing those samples bacause with the little amount of samples in the study (12 per DEseq2 object). Without doing this, those samples would have been fairly influential, making the model less effective. <br>
Here we used the 5h dataset to fit the linear model because of the simple fact that the size factors are spread over a wider range (the coverage between the samples is more variable) compared to the 3h datasets and therefore, the estimate of the coefficient is more stable. A better approach would have been to downsample the fastq files to different sizes, run the Slamdunk pipeline also on the downsampled files and use these read-counts to fit the linear model mentioned above.

## Linear model fitting
```{r, eval=FALSE}
lm1 <- lm(
    sizeFactors(dds_list[["Nascent_5h"]]) [metadata_list[["Nascent_5h"]]$Treatment != "B"] ~ 
    sizeFactors(dds_list[["Total_5h"]]) [metadata_list[["Nascent_5h"]]$Treatment != "B"]
  )

df <- data.frame(Total_3h = sizeFactors(dds_list[["Total_3h"]]), Nascent_3h =sizeFactors(dds_list[["Nascent_3h"]]), Treatment = metadata_list[["Nascent_3h"]]$Treatment)
ggplot(df, aes(y = Nascent_3h, x = Total_3h, colour = Treatment)) + 
  geom_point() + xlim(0,1.6) + ylim(0, 1.6) +
  theme(plot.title = element_text(color = "grey50", size = 24),
        axis.title.y = element_text(color = "grey50", size = 22),
        axis.title.x = element_text(color = "grey50", size = 22),
        axis.text.x = element_text(color = "grey50", size = 16, angle = 90),
        axis.text.y = element_text(color = "grey50", size = 16),
        legend.title = element_text(color = "grey50", size = 24),
        legend.text = element_text(color = "grey50", size = 22)) +
        geom_abline(slope = coef(lm1)[2], intercept = coef(lm1)[1], colour = I("grey")) +
  ggsave(filename = "./Plots/Size_factors_calculated_without_B_3h.jpg", device = "jpeg", width = 8, height = 6)
```
<img src="C:/Users/mp674001/OneDrive - GSK/Desktop/SLAMseq/Plots/Size_factors_calculated_without_B_3h.jpg" height="400" />
<br>



```{r, eval=FALSE}
df <- data.frame(Total_5h = sizeFactors(dds_list[["Total_5h"]]), Nascent_5h =sizeFactors(dds_list[["Nascent_5h"]]), Treatment = metadata_list[["Nascent_5h"]]$Treatment)
ggplot(df, aes(y = Nascent_5h, x = Total_5h, colour = Treatment)) + 
  geom_point() + xlim(0,1.6) + ylim(0, 1.6) +
  theme(plot.title = element_text(color = "grey50", size = 24),
        axis.title.y = element_text(color = "grey50", size = 22),
        axis.title.x = element_text(color = "grey50", size = 22),
        axis.text.x = element_text(color = "grey50", size = 16, angle = 90),
        axis.text.y = element_text(color = "grey50", size = 16),
        legend.title = element_text(color = "grey50", size = 24),
        legend.text = element_text(color = "grey50", size = 22)) +
  geom_abline(slope = coef(lm1)[2], intercept = coef(lm1)[1], colour = I("grey")) +
  ggsave(filename = "./Plots/Size_factors_calculated_without_B_5h.jpg", device = "jpeg", width = 8, height = 6)
```
<img src="C:/Users/mp674001/OneDrive - GSK/Desktop/SLAMseq/Plots/Size_factors_calculated_without_B_5h.jpg" height="400" />
<br>

## Run again DESeq2 with correction for "global" effects 
Now we can use the fitted values for the size factors to re-run the DESeq2 analysis.
```{r, eval=FALSE}
fitted_size_factor <- lapply(
  X = c("Total_3h", "Total_5h"), 
  FUN = function(nm) sizeFactors(dds_list[[nm]]) * coef(lm1)[2] + coef(lm1)[1] # fitted values
  ) 
names(fitted_size_factor) <- c("Nascent_3h", "Nascent_5h")

dds_list_size_factor <- lapply(
  X = names(fitted_size_factor), 
  FUN = function(nm) {
    dds <- DESeqDataSetFromMatrix(countData = cts_list_DESeq2[[nm]], colData = metadata_list[[nm]], design = ~ Treatment)
    sizeFactors(dds) <- fitted_size_factor[[nm]]
    dds
    }
  )

names(dds_list_size_factor) <- names(fitted_size_factor)

dds_list_size_factor <- lapply(dds_list_size_factor, DESeq)

res_list_size_factor <- lapply(
  X = names(dds_list_size_factor), 
  FUN = function(nm) {
    all_levels <- levels(metadata_list[[nm]]$Treatment)
    A_level_index <- grep(pattern = "A", all_levels)
    A_level <- all_levels[A_level_index]
    all_levels_no_A <- all_levels[- A_level_index]
    z <- lapply(
      all_levels_no_A, 
      function(x) {
        y <- lfcShrink(dds_list_size_factor[[nm]], contrast = c("Treatment", x, A_level))
        return(y)
        }
      )
    names(z) <- all_levels_no_A
    return(z)
    }
  )

names(res_list_size_factor) <- paste0(names(dds_list_size_factor), "_fitted")
```

## Incorporate the "global" effect corrected results with the ones from the standard workflow 
```{r, eval=FALSE}
res_list <- c(res_list, res_list_size_factor)
res_list_no_NA <- res_list

res_list_no_NA <- lapply(
  res_list_no_NA, 
  function(x) lapply(
    x, 
    function(y) {
      y$padj[which(is.na(y$padj))] <- 1
      y
      }
    )
  )
```

# Results inspection
## MA plots
```{r, eval=FALSE}
dir.create("./Plots/MA")

lapply(1:length(res_list), function(j) {
  lapply(1:length(res_list[[j]]), function(i) {
    jpeg(paste0("./Plots/MA/", names(res_list[[j]])[i], "_", names(res_list)[j], ".jpg"), 
         width = 12, 
         height = 8, 
         units = "cm", 
         res = 140, 
         quality = 100
    )
    par(col.main = "grey30")
    par(col.lab = "grey30")
    par(col.sub = "grey30")
    par(col.axis = "grey30")
    par(mar = c(5,5,4,4))
    plot(res_list[[j]][[i]]$baseMean + 1, 
         res_list[[j]][[i]]$log2FoldChange, 
         main = gsub(pattern = "_",replacement = " ", paste(names(res_list[[j]])[i], "_", names(res_list)[j])), 
         log = "x", 
         pch = 19, 
         cex = 0.2,
         cex.main = 0.8,
         xlab = "Read Count", 
         ylab = "Log2\nFold Change", 
         bty = "n", 
         col = alpha("grey70", 0.3), 
         ylim = c(-3, 3)
    )
    points(res_list[[j]][[i]]$baseMean[res_list[[j]][[i]]$padj < 0.01] + 1, 
           res_list[[j]][[i]]$log2FoldChange[res_list[[j]][[i]]$padj < 0.01], 
           col = alpha("grey30", 0.9), 
           pch = 19, 
           cex = 0.3
    )    
    dev.off()
    
  })
})
```

Due to the fact that out of the 3 experimental coditions, only B shoes considerable effects, it is the only one shown hereafter. <br>

<img src="C:/Users/mp674001/OneDrive - GSK/Desktop/SLAMseq/Plots/MA/B_Nascent_3h.jpg" height="300" />
<img src="C:/Users/mp674001/OneDrive - GSK/Desktop/SLAMseq/Plots/MA/B_Nascent_3h_fitted.jpg" height="300" />
<br>
Note that after "global" effect correction (labeled as "fitted" in the figure) there is a reduction of up-regulated transcripts and an increment in down-regulated ones. The same happens in the 5h dataset (below) <br>

<img src="C:/Users/mp674001/OneDrive - GSK/Desktop/SLAMseq/Plots/MA/B_Total_3h.jpg" height="300" />
<br>
At 3h it is clear that the nascent library has much more power in detecting transcriptional effects than a standard 3' library (labeled as "total" in the figure).
<br>
<img src="C:/Users/mp674001/OneDrive - GSK/Desktop/SLAMseq/Plots/MA/B_Nascent_5h.jpg" height="300" />
<img src="C:/Users/mp674001/OneDrive - GSK/Desktop/SLAMseq/Plots/MA/B_Nascent_5h_fitted.jpg" height="300" />
<img src="C:/Users/mp674001/OneDrive - GSK/Desktop/SLAMseq/Plots/MA/B_Total_5h.jpg" height="300" />
<br>
At 5h the nascent library does not seem to provide significant gains compared to the standard 3' library (labeled as "total" in the figure). This happens because the "total" library has around 20X the coverage compared to the nascent library. If the fastq are downsampled to the same amount of reads as the nascent library, the total library loses most of the differentially-expressed genes (data not shown). Therefore, in SLAM-seq analysis, 2 factors (treatment-time and loss of coverage due to the fact that the minority of the reads bear the T-->C conversion) pulling in opposite directions determine if performing SLAM-seq provide any advantage compared to a standard transcriptomics. At 3h it is clear that the nascent library have higher power than the standard 3' one. At 5h this is not clear and possibly, for longer timepoints (24-48h) it may not make sense at all to create SLAM-seq libraries. 
<br>
<img src="C:/Users/mp674001/OneDrive - GSK/Desktop/SLAMseq/Plots/MA/B_Total_24h.jpg" height="300" />

## Correlation plots: significance
```{r, eval=FALSE}
dir.create("./Plots/Log2FC_correlations_ggplot2/")

lapply(
  X = 1:nrow(expand.grid(1:length(res_list), 1:length(res_list))), 
  FUN = function(x) {
      comb1 <- expand.grid(1:length(res_list), 1:length(res_list))
      i <- comb1[x, 1]
      j <- comb1[x, 2]
      nm_i <- gsub("_", " ", names(res_list)[i]); print(nm_i)
      nm_j <- gsub("_", " ", names(res_list)[j]); print(nm_j)
      
      lapply(
        X = 1:length(res_list[[i]]), 
        FUN = function(n, nm_i, nm_j) {
            df <- data.frame(x1 = res_list[[i]][[n]]$log2FoldChange, y1 = res_list[[j]][[n]]$log2FoldChange)
            significance = rep("Not-significant", nrow(df))
            significance[res_list[[i]][[n]]$padj <= 0.01] <- nm_i
            significance[res_list[[j]][[n]]$padj <= 0.01] <- nm_j
            significance[res_list[[j]][[n]]$padj <= 0.01 & res_list[[i]][[n]]$padj <= 0.01] <- "Both"
            df$Significance = significance
            try(df$Significance <- factor(df$Significance, levels = c("Not-significant", nm_i, nm_j, "Both")))
            
            ggplot(df, aes(x = x1, y = y1, colour = Significance, alpha = Significance)) + 
              geom_point() + 
              xlim(-3, 3) +
              ylim(-3, 3) +
              xlab(nm_i) +
              ylab(nm_j) +
              labs(title = names(res_list[[i]])[n]) +
              scale_colour_manual(values=c("#999999", "#E69F00", "#56B4E9", "#9ED68B")) +
              theme(plot.title = element_text(color = "grey50", size = 22),
                    axis.title.y = element_text(color = "grey50", size = 22),
                    axis.title.x = element_text(color = "grey50", size = 22),
                    axis.text.x = element_text(color = "grey50", size = 16),
                    axis.text.y = element_text(color = "grey50", size = 16),
                    legend.title = element_text(color = "grey50", size = 18),
                    legend.text = element_text(color = "grey50", size = 18),
                    legend.key = element_rect(colour = NA, fill = NA),
                    legend.position = c(0.25, 0.85),
                    legend.background = element_rect(colour = NA, fill = NA)
                    )
              ggsave(
                    filename = paste0("./Plots/Log2FC_correlations_ggplot2/", names(res_list[[i]])[n], "_", nm_i, "_", nm_j, ".jpeg"), 
                    device = "jpeg", width = 6, height = 6
                    )
            },
        nm_i = nm_i, nm_j = nm_j)
      }
  )
```

<img src="C:/Users/mp674001/OneDrive - GSK/Desktop/SLAMseq/Plots/Log2FC_correlations_ggplot2/B_Nascent 3h fitted_Nascent 3h.jpeg" height="400" />
<img src="C:/Users/mp674001/OneDrive - GSK/Desktop/SLAMseq/Plots/Log2FC_correlations_ggplot2/B_Nascent 5h fitted_Nascent 5h.jpeg" height="400" />
<br>
From these scatterplots, we can verify that the "global" effect correction (labelesd as "fitted") introduces just a small shift in the log2 fold changes. This results in a considerable amount of differentially-expressed transcripts that vary between the 2 cases.
<br>
<img src="C:/Users/mp674001/OneDrive - GSK/Desktop/SLAMseq/Plots/Log2FC_correlations_ggplot2/B_Nascent 3h_Total 3h.jpeg" height="400" />
<img src="C:/Users/mp674001/OneDrive - GSK/Desktop/SLAMseq/Plots/Log2FC_correlations_ggplot2/B_Nascent 5h_Total 5h.jpeg" height="400" />
<br>
These 2 are amongst the most important exploratory plots of the whole analysis. From the MA it was already clear that quantitatively speaking, at 5h the total library had a similar power compared to the nascent library. Here we can appreciate that the 2 dataset correlate well. The same cannot be said for the 3h datasets because here the total and nascent libraries do not show high correlation. In particular, the nascent library have a much broader log2 fold changes distribution, proving how much more sensitive the nascent library is for short treatment times. 





## Dispersion stats
```{r, eval=FALSE}
jpeg("./Plots/Dispersion.jpeg", 
     width = 6, 
     height = 8, 
     units = "cm", 
     res = 140, 
     quality = 100
     )
  par(col.main = "grey30")
  par(col.lab = "grey30")
  par(col.sub = "grey30")
  par(col.axis = "grey30")
  par(mar = c(6,5,0.2,0.2))
  boxplot(lapply(dds_list, dispersions), 
          col = c("#3A9E60", "#7A9FB6", "#B678AF", "#DA5F5F", "#F2AE48"), 
          border = c("#3A9E60", "#7A9FB6", "#B678AF", "#DA5F5F", "#F2AE48"), 
          lty = 1,  outline = F, medcol = "white", staplelty = 0, lwd = 2, medlwd = 2, boxlty = 0, 
          ylab = "Dispersion", ylim = c(0,2.3), las = 2)
dev.off()
```

<img src="C:/Users/mp674001/OneDrive - GSK/Desktop/SLAMseq/Plots/Dispersion.jpeg" height="400" />
<br>
The higher dispersion on the nascent and 24h libraries is due to the lower amount of reads.

# Estimating the relative transcription rates
In this section we will explore another feature of the nascent transcriptomics that is not available with the standard methods. 


## Restructure the dataset 
The dataset in the form that we used so far is not suited for this analysis since we need the nascent and the total counts in the same count matrix. The first step therefore is be to join along the column axis the nascent and total count-matrixes, and label them accordingly.

```{r, eval=FALSE}
cts_list_symbols2 <- cts_list_symbols
cts_list_symbols2 <- lapply(
  names(cts_list_symbols2), 
  function(nm) {
    colnames(cts_list_symbols2[[nm]]) <- paste0(colnames(cts_list_symbols2[[nm]]), "_", nm)
    cts_list_symbols2[[nm]]
    }
  )

metadata_nascent <- metadata
metadata_total <- metadata

metadata_nascent$Sample_Name <- paste0(metadata_nascent$Sample_Name, "_nascent")
metadata_total$Sample_Name <- paste0(metadata_total$Sample_Name, "_total")

metadata_nascent$Labeling <- "nascent"
metadata_total$Labeling <- "total"

cts_nascent_total <- do.call("cbind", cts_list_symbols2)
metadata_nascent_total <- rbind(metadata_nascent, metadata_total)
```

## Filtering out the confounding datasets
For this procedure we chose to use just the reference condition (Condition A) in order to avoid the situation in which experimental perturbation affect the estimate of the transcription rates.
```{r, eval=FALSE}
metadata_nascent_total <- metadata_nascent_total[metadata_nascent_total$Library_type == "SLAM", ]
metadata_nascent_total <- metadata_nascent_total[metadata_nascent_total$Treatment == "A", ]
```


## DESeq2 model fitting
In this section we will perform the acctual estimate of the transcription rates.<br>
The proportion of reads labeled as nascent versus the total ones can be used to infer the relative transcription rate of each gene. Obviously, this is not a dedicated experiment with the aim of calculating precise turnover or half-lives time for every transcript. In order to do this, it would be necessary to setup a time course with different S4U labeling times spanning a wide time-window, such as 0-36h. Even though this time-course was not done, it is still possible to infer relative transcription rates.
This step cannot be done by simply computing a ratio between the nascent counts and the total counts because of the high noise on the low read-count region of the transcriptome (in such region the variation will be inflated just because of tiny variations in the read counts).<br>
The fundation of the method in this case is to regress out the total read-count. This is done in DESeq2 by specifying as reference factor the total read-count libraries. Additionally, DESeq2 does one very important thing: it shrinks the log2 fold changes thereby correcting the problem mentioned above.


```{r, eval=FALSE}
cts_nascent_total <- cts_nascent_total[, metadata_nascent_total$Sample_Name] 
metadata_nascent_total$Labeling <- factor(metadata_nascent_total$Labeling, levels = c("total", "nascent"))
metadata_nascent_total$Labeling <- relevel(metadata_nascent_total$Labeling, ref = "total")
metadata_nascent_total$Time <- as.factor(metadata_nascent_total$Time)
metadata_nascent_total$Treatment <- as.factor(metadata_nascent_total$Treatment)

rm(list = c("metadata_nascent", "metadata_total"))

dds_nascent_total <- DESeqDataSetFromMatrix(countData = cts_nascent_total, colData = metadata_nascent_total, design = ~ Time + Labeling)
dds_nascent_total <- DESeq(dds_nascent_total)
res_nascent_total <- results(dds_nascent_total)
res_nascent_total_lfc_normal <- lfcShrink(dds_nascent_total, contrast = c("Labeling", "nascent", "total"))

res_nascent_total_lfc_normal[is.na(res_nascent_total_lfc_normal$log2FoldChange), ] <- 0
```


## Incorporate the transcriptional rate scores into the main result object
The log2 fold changes obtained from the DESeq2 results table (nascent vs total) are added to each one of the result table previously calculated.

```{r, eval=FALSE}
res_list <- lapply(
  res_list, 
  function(x) lapply(
    x, 
    function(y) {
      y$Turnover <- res_nascent_total_lfc_normal$log2FoldChange
      y
      }
    )
  )

res_list_gene_names <- lapply(
  res_list, 
  function(x) lapply(
    x, 
    function(y) {
      y$Gene_id <- rownames(y) 
      y
      }
    )
   )
```

## Evaluation of the method
### MA plot
```{r, eval=FALSE}
jpeg("./Plots/MA/Transcription_rate.jpg", 
         width = 12, 
         height = 8, 
         units = "cm", 
         res = 140, 
         quality = 100
    )
    par(col.main = "grey30")
    par(col.lab = "grey30")
    par(col.sub = "grey30")
    par(col.axis = "grey30")
    par(mar = c(5,5,4,4))
    plot(res_nascent_total_lfc_normal$baseMean + 1, 
         res_nascent_total_lfc_normal$log2FoldChange, 
         main = "Turnover", 
         log = "x", 
         pch = 19, 
         cex = 0.2,
         cex.main = 0.8,
         xlab = "Read Count", 
         ylab = "Log2\nFold Change", 
         bty = "n", 
         col = alpha("grey70", 0.3), 
         ylim = c(-5, 5)
    )
dev.off()
```
<img src="C:/Users/mp674001/OneDrive - GSK/Desktop/SLAMseq/Plots/MA/Transcription_rate.jpg" height="400" />

### Transcription rate distribution
```{r, eval=FALSE}
jpeg("./Plots/Transcription_rate_distribution.jpg", 
         width = 12, 
         height = 8, 
         units = "cm", 
         res = 140, 
         quality = 100
    )
    par(col.main = "grey30")
    par(col.lab = "grey30")
    par(col.sub = "grey30")
    par(col.axis = "grey30")
    par(mar = c(5,5,4,4))

    res_nascent_total_lfc_normal$log2FoldChange %>% hist(br = 100, main = "Turnover", xlab = "Log2 Fold change (Nascent/Total)")
dev.off()
```
<img src="C:/Users/mp674001/OneDrive - GSK/Desktop/SLAMseq/Plots/Transcription_rate_distribution.jpg" height="400" />

### Transcription rate scores vs raw read counts
```{r, eval=FALSE}
df <- data.frame(total = cts_list_symbols[["total"]][,1], # select one random sample: sample 1
                 nascent = cts_list_symbols[["nascent"]][, 1], # select one random sample: sample 1
                 Turnover = res_nascent_total_lfc_normal$log2FoldChange # the transcription rates from the original DESeq2 result object
                 )
ggplot(df, aes(x = total, y = nascent, colour = Turnover)) + 
  geom_point(alpha = 0.6) + 
  scale_colour_gradient2(low ="darkcyan", mid = "white", high = "#7D618B", midpoint = 0.2) +
  scale_y_log10() +
  scale_x_log10() +
  theme(plot.title = element_text(color = "grey50", size = 24),
        axis.title.y = element_text(color = "grey50", size = 22),
        axis.title.x = element_text(color = "grey50", size = 22),
        axis.text.x = element_text(color = "grey50", size = 16, angle = 90),
        axis.text.y = element_text(color = "grey50", size = 16),
        legend.title = element_text(color = "grey50", size = 24),
        legend.text = element_text(color = "grey50", size = 22)) +
  ggsave(filename = "./Plots/Sample_1_nascent_vs_total_turnover_counts.jpg", device = "jpeg", width = 8, height = 6)
```

<img src="C:/Users/mp674001/OneDrive - GSK/Desktop/SLAMseq/Plots/Sample_1_nascent_vs_total_turnover_counts.jpg" height="400" />
<br>
As shown in this figure, DESeq2 deflate the log2 fold change on the lower read counts region, showing a fairly independent relationship between read counts and transcription rate.

### Correlation plots: transcription rate
```{r, eval=FALSE}
dir.create("./Plots/Log2FC_correlations_ggplot2_transcription_rate")

lapply(
  X = 1:nrow(expand.grid(1:length(res_list), 1:length(res_list))), 
  FUN = function(x) {
      comb1 <- expand.grid(1:length(res_list), 1:length(res_list))
      i <- comb1[x, 1]
      j <- comb1[x, 2]
      nm_i <- gsub("_", " ", names(res_list)[i]); print(nm_i)
      nm_j <- gsub("_", " ", names(res_list)[j]); print(nm_j)
      lapply(
        X = 1:length(res_list[[i]]), 
        FUN = function(n, nm_i, nm_j) {
            df <- data.frame(x1 = res_list[[i]][[n]]$log2FoldChange, y1 = res_list[[j]][[n]]$log2FoldChange, Turnover = res_list[[j]][[n]]$Turnover)
            ggplot(df, aes(x = x1, y = y1, colour = Turnover)) + 
              geom_point(alpha = 0.6) + 
              scale_colour_gradient2(low ="darkcyan", mid = "white",high = "#7D618B", midpoint = 0.2) +
              xlim(-3, 3) +
              ylim(-3, 3) +
              xlab(nm_i) +
              ylab(nm_j) +
              labs(title = names(res_list[[i]])[n]) +
              theme(plot.title = element_text(color = "grey50", size = 22),
                    axis.title.y = element_text(color = "grey50", size = 22),
                    axis.title.x = element_text(color = "grey50", size = 22),
                    axis.text.x = element_text(color = "grey50", size = 16),
                    axis.text.y = element_text(color = "grey50", size = 16),
                    legend.title = element_text(color = "grey50", size = 18),
                    legend.text = element_text(color = "grey50", size = 18),
                    legend.key = element_rect(colour = NA, fill = NA),
                    legend.position = c(0.15, 0.75),
                    legend.background = element_rect(colour = NA, fill = NA))
            ggsave(filename = paste0("./Plots/Log2FC_correlations_ggplot2_transcription_rate/", names(res_list[[i]])[n], "_", nm_i, "_", nm_j, ".jpeg"), device = "jpeg", width = 6, height = 6)
            }, 
            nm_i = nm_i, nm_j = nm_j)
      }
  )
```

<img src="C:/Users/mp674001/OneDrive - GSK/Desktop/SLAMseq/Plots/Log2FC_correlations_ggplot2_transcription_rate/B_Nascent 3h_Total 3h.jpeg" height="400" />
<img src="C:/Users/mp674001/OneDrive - GSK/Desktop/SLAMseq/Plots/Log2FC_correlations_ggplot2_transcription_rate/B_Nascent 5h_Total 5h.jpeg" height="400" />
<br>
These are the same plots shown in section 4.2, just, the points are labeled with the transcription rate score. Here we can appreciate the relationship between the log2 fold changes (in both nascent and totla libraries) and the transcription rate. The transcripts that are closer to the main diagonal, or in other words, the ones whose log2 fold change in the 5h total library correlate the most with the nascent library, tend to have faster transcription rate.


### Relationship between transcription rate and statistical significance
```{r, eval=FALSE}
jpeg("./Plots/Condition_B_transcription_rate_boxplots_significant.jpg", 
     width = 6, 
     height = 8, 
     units = "cm", 
     res = 140, 
     quality = 100
     )
  par(col.main = "grey50")
  par(col.lab = "grey50")
  par(col.sub = "grey50")
  par(col.axis = "grey50")
  par(mar = c(8,4,0.2,0.2))
  boxplot(
    lapply(
      X = res_list, 
      FUN = function(x) {
        y <- x[["B"]] # select only condition "B"
        y <- y[which(y$padj <= 0.01), ] # select only the significant transcripts
        y$Turnover
        }
      )[c(2, 4, 5, 6, 7)], 
    col = c("#7A9FB6", "#DA5F5F", "#F2AE48", "#3A9E60", "#B678AF"), 
    border = c("#7A9FB6", "#DA5F5F", "#F2AE48", "#3A9E60", "#B678AF"), 
    lty = 1,  outline = F, medcol = "white", staplelty = 0, lwd = 2, medlwd = 2, boxlty = 0,
    ylab = "Turnover",
    las = 2
    )
dev.off()
```
<img src="C:/Users/mp674001/OneDrive - GSK/Desktop/SLAMseq/Plots/Condition_B_transcription_rate_boxplots_significant.jpg" height="400" />
<br>
This is arguably the most important figure of the whole analysis.  
<br>
In the previous section we looked at the relationship between the transcription rate and the log2 fold changes (differential expression). In this section we aim to quantify if there is a relationship between statistical significance at different timepoints and the transcription rate. We show this just for the significantly differentially expressed transcripts for condition "B". 
<br>
Looking just at the samples from the total libraries, it is possible to see a trend that extends from 3h to 24h. Transcripts that are found significantly differentially expressed at early timepoints tend to have a higher transcription rate (turnover), while transcripts that are significant at later points tend to have s slower transcription rate. This is relevant because often people refer to the transcripts that are found differentially expressed at the later timepoints as secondary effects (for example belonging to a second wave of transcriptional changes). Is it possible that at least in some cases this has to do simply with the fact that those transcripts need to undergo a sufficient amount of turnover in order to show detectable changes. 
<br>
Last, the nascent libraries allow the identification of transcriptional changes independently of the transcription rate.


```{r}
sessionInfo()
```


